# Day 2 rule set: evidence-aware, ontology-aware scoring
rules:
  - id: type_domain_range_valid
    description: Domain/range matches expected biomedical categories
    weight: 0.8
    when:
      all:
        - fact: type.domain_valid
          op: equals
          value: true
        - fact: type.range_valid
          op: equals
          value: true
    because: "because the subject ({type.domain_category}) -> object ({type.range_category}) relation is allowed"

  - id: type_domain_range_violation
    description: Domain/range invalid for predicate
    weight: -1.2
    when:
      any:
        - fact: type.domain_valid
          op: equals
          value: false
        - fact: type.range_valid
          op: equals
          value: false
    because: "because the subject/object categories are incompatible ({type.domain_category} -> {type.range_category})"

  - id: ontology_closure_hpo
    description: Entities carry ontology ancestry (HPO/MONDO/etc)
    weight: 0.4
    when:
      any:
        - fact: ontology.subject_has_ancestors
          op: equals
          value: true
        - fact: ontology.object_has_ancestors
          op: equals
          value: true
    because: "because ontology closure was available for at least one entity"

  - id: ontology_sibling_conflict
    description: Subject/object appear to be ontology siblings rather than parent/child
    weight: -0.6
    when:
      all:
        - fact: ontology.is_sibling_conflict
          op: equals
          value: true
    because: "because {ontology.subject_label} and {ontology.object_label} look like ontology siblings (shared ancestors: {ontology.sibling_shared_ancestors})"

  - id: retraction_gate
    description: Fail hard if any supporting citation is retracted
    weight: -1.5
    when:
      any:
        - fact: evidence.retracted_count
          op: gt
          value: 0
    because: "because one or more citations are retracted: {evidence.retracted}"

  - id: expression_of_concern
    description: Down-weight citations marked as expressions of concern
    weight: -0.5
    when:
      any:
        - fact: evidence.concern_count
          op: gt
          value: 0
    because: "because some citations have expressions of concern: {evidence.concerns}"

  - id: self_negation_conflict
    description: Claim explicitly negates the predicate or cites refuting evidence
    weight: -1.3
    when:
      any:
        - fact: conflicts.qualifier_negated
          op: equals
          value: true
        - fact: conflicts.has_refuting_evidence
          op: equals
          value: true
    because: "because the claim carries a negation qualifier or refuting evidence (sources: {conflicts.negation_sources}; refuting={conflicts.refuting_evidence})"

  - id: opposite_predicate_same_context
    description: Predicate direction conflicts with known context for this subject/object pair
    weight: -1.3
    when:
      all:
        - fact: conflicts.opposite_predicate_same_context
          op: equals
          value: true
    because: "because the predicate polarity ({conflicts.claim_predicate_polarity}) opposes context evidence ({conflicts.context_predicate_polarity}); context predicates: {conflicts.context_predicate_examples}"

  - id: extraction_low_confidence
    description: Low-confidence extraction with hedging language and fallback predicate
    weight: -1.1
    when:
      all:
        - fact: extraction.is_low_confidence
          op: equals
          value: true
    because: "because the predicate was inferred with hedging language ({extraction.hedging_terms}) and no supporting citations"

  - id: multi_source_bonus
    description: Reward multiple independent sources
    weight: 0.3
    when:
      all:
        - fact: evidence.has_multiple_sources
          op: equals
          value: true
    because: "because the claim cites multiple sources ({claim.citation_count})"

  - id: minimal_evidence
    description: Require at least one supporting citation
    weight: -0.6
    when:
      any:
        - fact: claim.citation_count
          op: lte
          value: 0
    because: "because no PMIDs/DOIs were supplied"

  - id: disgenet_support_bonus
    description: Curated KG (Monarch/DisGeNET) supports the gene–disease association
    weight: 0.5
    when:
      all:
        - fact: curated_kg.curated_kg_match
          op: equals
          value: true
    because: "because a curated knowledge graph (e.g., Monarch or DisGeNET) reports a supporting association for this gene–disease pair"

  - id: disgenet_missing_support_penalty
    description: Penalize lack of DisGeNET support when checked
    weight: -0.3
    when:
      all:
        - fact: curated_kg.disgenet_checked
          op: equals
          value: true
        - fact: curated_kg.disgenet_support
          op: equals
          value: false
    because: "because DisGeNET does not report a high-scoring association for this gene–disease pair"

  - id: structured_literature_support
    description: SemMedDB/INDRA report structured triples supporting the claim
    weight: 0.4
    when:
      all:
        - fact: literature.has_structured_support
          op: equals
          value: true
    because: "because structured literature sources (SemMedDB/INDRA) contain matching subject–predicate–object triples for this claim"

  - id: tissue_mismatch
    description: Claimed tissue context does not match expected tissue for this pathway/process
    weight: -0.6
    when:
      all:
        - fact: tissue.is_mismatch
          op: equals
          value: true
    because: "because {tissue.mismatch_details}"

  # ---------------------------------------------------------------------------
  # NLI Scoring Rules (Day 3)
  # ---------------------------------------------------------------------------

  - id: nli_multi_source_support
    description: Multiple independent sources provide NLI support
    weight: 0.5
    when:
      all:
        - fact: text_nli.n_support
          op: gte
          value: 2
    because: "because {text_nli.n_support} independent papers provide supporting evidence (N_sup ≥ 2)"

  - id: nli_single_source_support
    description: At least one source provides NLI support
    weight: 0.2
    when:
      all:
        - fact: text_nli.n_support
          op: gte
          value: 1
        - fact: text_nli.n_support
          op: lt
          value: 2
    because: "because at least one paper provides supporting evidence (N_sup = 1)"

  - id: nli_strong_support_margin
    description: Literature margin strongly supports the claim
    weight: 0.4
    when:
      all:
        - fact: text_nli.m_lit
          op: gte
          value: 1.0
    because: "because literature margin is strongly positive (M_lit = {text_nli.m_lit:.2f} ≥ 1.0)"

  - id: nli_contradiction_detected
    description: At least one source contradicts the claim
    weight: -0.6
    when:
      all:
        - fact: text_nli.n_contradict
          op: gte
          value: 1
    because: "because {text_nli.n_contradict} paper(s) contradict the claim (N_con ≥ 1)"

  - id: nli_negative_margin
    description: Literature margin is negative (more contradiction than support)
    weight: -0.8
    when:
      all:
        - fact: text_nli.m_lit
          op: lt
          value: 0
    because: "because literature margin is negative (M_lit = {text_nli.m_lit:.2f} < 0, contradictions outweigh support)"

  - id: nli_predicate_mismatch
    description: Evidence uses weaker predicates than the claim
    weight: -0.3
    when:
      all:
        - fact: text_nli.claim_predicate_class
          op: equals
          value: "causal"
        - fact: text_nli.predicate_mismatch_count
          op: gte
          value: 2
    because: "because causal claim is supported only by association-level evidence ({text_nli.predicate_mismatch_count} predicate mismatches)"

  - id: nli_hedged_claim_penalty
    description: Claim uses hedging language (may, might, could)
    weight: -0.15
    when:
      all:
        - fact: text_nli.claim_is_hedged
          op: equals
          value: true
    because: "because claim uses hedging language ({text_nli.hedging_terms})"

  - id: nli_no_evidence_checked
    description: No abstracts were available for NLI verification
    weight: -0.05
    when:
      all:
        - fact: text_nli.checked
          op: equals
          value: false
    because: "because no abstracts were available for text-level NLI verification (neutral signal)"
